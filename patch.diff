#cat patch.diff
#git apply --stat patch.diff       # shows which files will be changed
#git apply --check patch.diff      # verifies patch can apply cleanly
#git apply patch.diff


diff --git a/notebooks/5_hyperparameter_tuning.py b/notebooks/5_hyperparameter_tuning.py
index f913496c6edf0fddc000bb5d83695ad559c60e4b..6f76936c50a05f6c407b6fae082e37dfa38fff7f 100644
--- a/notebooks/5_hyperparameter_tuning.py
+++ b/notebooks/5_hyperparameter_tuning.py
@@ -26,51 +26,51 @@
 import os, sys
 SRC_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src'))
 if SRC_PATH not in sys.path:
     sys.path.insert(0, SRC_PATH)
 
 from utils import (
     setup_environment, load_or_process_dataframe, save_plot, style_df, prepare_data_for_modeling, log_and_print
 )
 from modeling import split_data, scale_features, apply_power_transform, evaluate_model
 from viz import plot_parity_logscale
 import pandas as pd
 import numpy as np
 import json
 import joblib
 from sklearn.ensemble import RandomForestRegressor
 from xgboost import XGBRegressor
 import shap
 import matplotlib.pyplot as plt
 from IPython.display import display
 from sklearn.model_selection import RandomizedSearchCV
 from scipy.stats import randint, uniform
 
 # --- Setup environment and paths ---
 setup_environment()
 USE_CLUSTER_FEATURES = False
-CACHE_PATH = '../data/processed/featurized.pkl'
+CACHE_PATH = '../data/processed/featurized.parquet'
 SELECTED_FEATURES_PATH = '../data/processed/selected_features_xgb.json'
 FINAL_MODEL_PATH = '../models/tuned_xgboost_model.joblib'
 PLOTS_DIR = '../plots/5_hyperparameter_tuning'
 os.makedirs(PLOTS_DIR, exist_ok=True)
 PARITY_PLOT_PATH = os.path.join(PLOTS_DIR, 'tuned_xgb_model_parity_plot.pdf')
 SHAP_PLOT_PATH = os.path.join(PLOTS_DIR, 'tuned_xgb_model_shap_summary.pdf')
 
 # --- Load featurized data using robust utility ---
 df = load_or_process_dataframe(cache_path=CACHE_PATH)
 log_and_print(f"Featurized dataframe shape: {df.shape}")
 
 # %% [markdown]
 # ## 1. Load and Prepare Data
 # 
 # We load the same featurized data and the list of selected features to ensure consistency with the modeling notebook.
 
 # %%
 # Prepare data for modeling
 X, y = prepare_data_for_modeling(df, target_col='thermal_conductivity')
 
 # %%
 # Conditionally add cluster features based on the flag
 if USE_CLUSTER_FEATURES:
     log_and_print("Generating cluster features...")
     from sklearn.preprocessing import StandardScaler
